{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 15:23:13.067984: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-03 15:23:13.116202: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-03 15:23:13.116271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-03 15:23:13.117399: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-03 15:23:13.124263: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-03 15:23:14.061595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load requried features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 15:23:16.725442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 15:23:16.789164: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 15:23:16.789208: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 15:23:16.792249: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 15:23:16.792329: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 15:23:16.792348: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 15:23:18.387117: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 15:23:18.387191: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 15:23:18.387197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-03 15:23:18.387221: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 15:23:18.387237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3411 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "    \"user_gender\": int(x[\"user_gender\"]),\n",
    "    \"user_zip_code\": x[\"user_zip_code\"],\n",
    "    \"user_occupation_text\": x[\"user_occupation_text\"],\n",
    "    \"bucketized_user_age\": int(x[\"bucketized_user_age\"]),\n",
    "    \"timestamp\": x[\"timestamp\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(min_timestamp, max_timestamp, num=1000,)\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"user_id\"]))))\n",
    "unique_occupations = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"user_occupation_text\"]))))\n",
    "unique_zipcodes = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"user_zip_code\"]))))\n",
    "unique_genders = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"user_gender\"]))))\n",
    "unique_ages = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"bucketized_user_age\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "### Query model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, int(len(unique_user_ids) ** 0.25)),\n",
    "        ])\n",
    "        self.timestamp_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "            tf.keras.layers.Embedding(len(timestamp_buckets) + 1, int(len(timestamp_buckets) ** 0.25)),\n",
    "        ])\n",
    "        self.normalized_timestamp = tf.keras.layers.Normalization(axis=None)\n",
    "        self.normalized_timestamp.adapt(timestamps)\n",
    "        \n",
    "        self.occupation_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_occupations, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_occupations) + 1, int(len(unique_occupations) ** 0.25)),\n",
    "        ])\n",
    "        self.zipcode_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_zipcodes, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_zipcodes) + 1, int(len(unique_zipcodes) ** 0.25)),\n",
    "        ])\n",
    "        self.gender_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.IntegerLookup(vocabulary=unique_genders, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_genders) + 1, int(len(unique_genders) ** 0.25)),\n",
    "        ])\n",
    "        self.age_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.IntegerLookup(vocabulary=unique_ages, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_ages) + 1, int(len(unique_ages) ** 0.25)),\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Take the input dictionary, pass it through each input layer,\n",
    "        # and concatenate the result.\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "            tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
    "            self.occupation_embedding(inputs[\"user_occupation_text\"]),\n",
    "            self.zipcode_embedding(inputs[\"user_zip_code\"]),\n",
    "            self.gender_embedding(inputs[\"user_gender\"]),\n",
    "            self.age_embedding(inputs[\"bucketized_user_age\"]),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding user queries.\"\"\"\n",
    "    \n",
    "    def __init__(self, layer_sizes, projection_dim=None):\n",
    "        \"\"\"Model for encoding user queries.\n",
    "        \n",
    "        Args:\n",
    "          layer_sizes:\n",
    "            A list of integers where the i-th entry represents the number of units\n",
    "            the i-th layer contains.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # We first use the user model for generating embeddings.\n",
    "        self.embedding_model = UserModel()\n",
    "\n",
    "        # Cross & Dense layer\n",
    "        self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "            projection_dim=projection_dim,\n",
    "            kernel_initializer=\"glorot_uniform\")\n",
    "        \n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "        \n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "        \n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        feature_embedding = self._cross_layer(feature_embedding)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        max_tokens = 10_000\n",
    "        \n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "              vocabulary=unique_movie_titles,mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, 32)\n",
    "        ])\n",
    "        \n",
    "        self.title_vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_tokens)\n",
    "        \n",
    "        self.title_text_embedding = tf.keras.Sequential([\n",
    "          self.title_vectorizer,\n",
    "          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "          tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        ])\n",
    "        \n",
    "        self.title_vectorizer.adapt(movies)\n",
    "\n",
    "    def call(self, titles):\n",
    "        return tf.concat([\n",
    "            self.title_embedding(titles),\n",
    "            self.title_text_embedding(titles),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding movies.\"\"\"\n",
    "    \n",
    "    def __init__(self, layer_sizes, projection_dim=None):\n",
    "        \"\"\"Model for encoding movies.\n",
    "        \n",
    "        Args:\n",
    "          layer_sizes:\n",
    "            A list of integers where the i-th entry represents the number of units\n",
    "            the i-th layer contains.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_model = MovieModel()\n",
    "\n",
    "        # Cross & Dense layer\n",
    "        self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "            projection_dim=projection_dim,\n",
    "            kernel_initializer=\"glorot_uniform\")\n",
    "        \n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "        \n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "        \n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        feature_embedding = self._cross_layer(feature_embedding)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "    def __init__(self,\n",
    "                 rating_weight: float,\n",
    "                 query_layer_sizes,\n",
    "                 candidate_layer_sizes,\n",
    "                 projection_dim=None):\n",
    "        assert query_layer_sizes[-1] == candidate_layer_sizes[-1], f'query and candidate embeddings of different sizes: {query_layer_sizes[-1]} and {candidate_layer_sizes[-1]}'\n",
    "        \n",
    "        super().__init__()\n",
    "        self.query_model = QueryModel(query_layer_sizes, projection_dim=projection_dim)\n",
    "        self.candidate_model = CandidateModel(candidate_layer_sizes, projection_dim=projection_dim)\n",
    "        # A small model to take in user and movie embeddings and predict ratings.\n",
    "        # We can make this as complicated as we want as long as we output a scalar\n",
    "        # as our prediction.\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "\n",
    "        # The tasks.\n",
    "        self.rating_task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        self.retrieval_task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.candidate_model),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = 1 - rating_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        query_embeddings = self.query_model({\n",
    "            \"user_id\": features[\"user_id\"],\n",
    "            \"user_gender\": features[\"user_gender\"],\n",
    "            \"user_zip_code\": features[\"user_zip_code\"],\n",
    "            \"user_occupation_text\": features[\"user_occupation_text\"],\n",
    "            \"bucketized_user_age\": features[\"bucketized_user_age\"],\n",
    "            \"timestamp\": features[\"timestamp\"],\n",
    "        })\n",
    "        candidate_embeddings = self.candidate_model(features[\"movie_title\"])\n",
    "\n",
    "        x = tf.concat([query_embeddings, candidate_embeddings], axis=1)\n",
    "    \n",
    "        return (\n",
    "            query_embeddings,\n",
    "            candidate_embeddings,\n",
    "            # We apply the multi-layered rating model to a concatentation of\n",
    "            # user and movie embeddings.\n",
    "            self.rating_model(x),\n",
    "        )\n",
    "    \n",
    "    def compute_loss(self, features, training=False):\n",
    "        ratings = features.pop(\"user_rating\")\n",
    "\n",
    "        query_embeddings, candidate_embeddings, rating_predictions = self(features)\n",
    "    \n",
    "        # We compute the loss for each task.\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(query_embeddings, candidate_embeddings)\n",
    "    \n",
    "        # And combine them using the loss weights.\n",
    "        return (self.rating_weight * rating_loss + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.1\n",
    "EPOCHS = 300\n",
    "MODEL_NAME = 'DNN-7-96_32-64_32-emb_0.25-cross_emb-2'\n",
    "\n",
    "class CustomModelCheckpoint(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Saves checkpoint on each validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, save_dir):\n",
    "        super().__init__()\n",
    "        self.save_dir = save_dir\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss = logs.get('val_loss')\n",
    "        acc100 = logs.get('val_factorized_top_k/top_100_categorical_accuracy')\n",
    "        rmse = logs.get('val_root_mean_squared_error')\n",
    "        if loss is not None:\n",
    "            cp_name = f'cp-{epoch:03d}_loss-{round(loss)}_acc100-{acc100:.4f}_rmse-{rmse:.4f}.ckpt'\n",
    "            self.model.save_weights(f'../models/{self.save_dir}/{cp_name}')\n",
    "            print(f'\\nSaved checkpoint to {cp_name}')\n",
    "\n",
    "cp_callback = CustomModelCheckpoint(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 15:23:53.347844: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f26d80079f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-03 15:23:53.347884: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-12-03 15:23:53.351762: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-03 15:23:53.790984: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1701606233.837909   69554 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 20s 275ms/step - root_mean_squared_error: 1.6443 - factorized_top_k/top_1_categorical_accuracy: 0.0468 - factorized_top_k/top_5_categorical_accuracy: 0.0746 - factorized_top_k/top_10_categorical_accuracy: 0.0894 - factorized_top_k/top_50_categorical_accuracy: 0.1471 - factorized_top_k/top_100_categorical_accuracy: 0.1860 - loss: 7410.8887 - regularization_loss: 0.0000e+00 - total_loss: 7410.8887\n",
      "Epoch 2/300\n",
      "40/40 [==============================] - 12s 231ms/step - root_mean_squared_error: 1.1965 - factorized_top_k/top_1_categorical_accuracy: 0.0401 - factorized_top_k/top_5_categorical_accuracy: 0.0705 - factorized_top_k/top_10_categorical_accuracy: 0.0910 - factorized_top_k/top_50_categorical_accuracy: 0.1636 - factorized_top_k/top_100_categorical_accuracy: 0.2087 - loss: 7205.7789 - regularization_loss: 0.0000e+00 - total_loss: 7205.7789\n",
      "Epoch 3/300\n",
      "40/40 [==============================] - 12s 228ms/step - root_mean_squared_error: 1.1610 - factorized_top_k/top_1_categorical_accuracy: 0.0393 - factorized_top_k/top_5_categorical_accuracy: 0.0636 - factorized_top_k/top_10_categorical_accuracy: 0.0790 - factorized_top_k/top_50_categorical_accuracy: 0.1443 - factorized_top_k/top_100_categorical_accuracy: 0.2018 - loss: 7127.3478 - regularization_loss: 0.0000e+00 - total_loss: 7127.3478\n",
      "Epoch 4/300\n",
      "40/40 [==============================] - 12s 218ms/step - root_mean_squared_error: 1.1076 - factorized_top_k/top_1_categorical_accuracy: 0.0205 - factorized_top_k/top_5_categorical_accuracy: 0.0405 - factorized_top_k/top_10_categorical_accuracy: 0.0542 - factorized_top_k/top_50_categorical_accuracy: 0.1224 - factorized_top_k/top_100_categorical_accuracy: 0.1909 - loss: 7065.3184 - regularization_loss: 0.0000e+00 - total_loss: 7065.3184\n",
      "Epoch 5/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 1.0831 - factorized_top_k/top_1_categorical_accuracy: 0.0184 - factorized_top_k/top_5_categorical_accuracy: 0.0376 - factorized_top_k/top_10_categorical_accuracy: 0.0517 - factorized_top_k/top_50_categorical_accuracy: 0.1258 - factorized_top_k/top_100_categorical_accuracy: 0.2031 - loss: 7169.5493 - regularization_loss: 0.0000e+00 - total_loss: 7169.5493\n",
      "Saved checkpoint to cp-004_loss-14039_acc100-0.1935_rmse-1.0920.ckpt\n",
      "40/40 [==============================] - 17s 351ms/step - root_mean_squared_error: 1.0831 - factorized_top_k/top_1_categorical_accuracy: 0.0184 - factorized_top_k/top_5_categorical_accuracy: 0.0376 - factorized_top_k/top_10_categorical_accuracy: 0.0517 - factorized_top_k/top_50_categorical_accuracy: 0.1258 - factorized_top_k/top_100_categorical_accuracy: 0.2031 - loss: 7001.4861 - regularization_loss: 0.0000e+00 - total_loss: 7001.4861 - val_root_mean_squared_error: 1.0920 - val_factorized_top_k/top_1_categorical_accuracy: 8.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0077 - val_factorized_top_k/top_10_categorical_accuracy: 0.0170 - val_factorized_top_k/top_50_categorical_accuracy: 0.0962 - val_factorized_top_k/top_100_categorical_accuracy: 0.1935 - val_loss: 14039.1377 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14039.1377\n",
      "Epoch 6/300\n",
      "40/40 [==============================] - 11s 215ms/step - root_mean_squared_error: 1.0639 - factorized_top_k/top_1_categorical_accuracy: 0.0151 - factorized_top_k/top_5_categorical_accuracy: 0.0314 - factorized_top_k/top_10_categorical_accuracy: 0.0453 - factorized_top_k/top_50_categorical_accuracy: 0.1260 - factorized_top_k/top_100_categorical_accuracy: 0.2172 - loss: 6960.0330 - regularization_loss: 0.0000e+00 - total_loss: 6960.0330\n",
      "Epoch 7/300\n",
      "40/40 [==============================] - 12s 220ms/step - root_mean_squared_error: 1.0515 - factorized_top_k/top_1_categorical_accuracy: 0.0106 - factorized_top_k/top_5_categorical_accuracy: 0.0261 - factorized_top_k/top_10_categorical_accuracy: 0.0391 - factorized_top_k/top_50_categorical_accuracy: 0.1256 - factorized_top_k/top_100_categorical_accuracy: 0.2209 - loss: 6934.2897 - regularization_loss: 0.0000e+00 - total_loss: 6934.2897\n",
      "Epoch 8/300\n",
      "40/40 [==============================] - 11s 213ms/step - root_mean_squared_error: 1.0359 - factorized_top_k/top_1_categorical_accuracy: 0.0088 - factorized_top_k/top_5_categorical_accuracy: 0.0246 - factorized_top_k/top_10_categorical_accuracy: 0.0397 - factorized_top_k/top_50_categorical_accuracy: 0.1329 - factorized_top_k/top_100_categorical_accuracy: 0.2361 - loss: 6907.8733 - regularization_loss: 0.0000e+00 - total_loss: 6907.8733\n",
      "Epoch 9/300\n",
      "40/40 [==============================] - 12s 222ms/step - root_mean_squared_error: 1.0371 - factorized_top_k/top_1_categorical_accuracy: 0.0061 - factorized_top_k/top_5_categorical_accuracy: 0.0203 - factorized_top_k/top_10_categorical_accuracy: 0.0351 - factorized_top_k/top_50_categorical_accuracy: 0.1338 - factorized_top_k/top_100_categorical_accuracy: 0.2432 - loss: 6880.9314 - regularization_loss: 0.0000e+00 - total_loss: 6880.9314\n",
      "Epoch 10/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 1.0287 - factorized_top_k/top_1_categorical_accuracy: 0.0069 - factorized_top_k/top_5_categorical_accuracy: 0.0225 - factorized_top_k/top_10_categorical_accuracy: 0.0381 - factorized_top_k/top_50_categorical_accuracy: 0.1442 - factorized_top_k/top_100_categorical_accuracy: 0.2576 - loss: 7026.5357 - regularization_loss: 0.0000e+00 - total_loss: 7026.5357\n",
      "Saved checkpoint to cp-009_loss-13949_acc100-0.2153_rmse-1.0434.ckpt\n",
      "40/40 [==============================] - 13s 260ms/step - root_mean_squared_error: 1.0287 - factorized_top_k/top_1_categorical_accuracy: 0.0069 - factorized_top_k/top_5_categorical_accuracy: 0.0225 - factorized_top_k/top_10_categorical_accuracy: 0.0381 - factorized_top_k/top_50_categorical_accuracy: 0.1442 - factorized_top_k/top_100_categorical_accuracy: 0.2576 - loss: 6861.7285 - regularization_loss: 0.0000e+00 - total_loss: 6861.7285 - val_root_mean_squared_error: 1.0434 - val_factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0085 - val_factorized_top_k/top_10_categorical_accuracy: 0.0192 - val_factorized_top_k/top_50_categorical_accuracy: 0.1088 - val_factorized_top_k/top_100_categorical_accuracy: 0.2153 - val_loss: 13949.4160 - val_regularization_loss: 0.0000e+00 - val_total_loss: 13949.4160\n",
      "Epoch 11/300\n",
      "40/40 [==============================] - 17s 281ms/step - root_mean_squared_error: 1.0308 - factorized_top_k/top_1_categorical_accuracy: 0.0062 - factorized_top_k/top_5_categorical_accuracy: 0.0217 - factorized_top_k/top_10_categorical_accuracy: 0.0389 - factorized_top_k/top_50_categorical_accuracy: 0.1510 - factorized_top_k/top_100_categorical_accuracy: 0.2695 - loss: 6839.6374 - regularization_loss: 0.0000e+00 - total_loss: 6839.6374\n",
      "Epoch 12/300\n",
      "40/40 [==============================] - 12s 217ms/step - root_mean_squared_error: 1.0219 - factorized_top_k/top_1_categorical_accuracy: 0.0053 - factorized_top_k/top_5_categorical_accuracy: 0.0213 - factorized_top_k/top_10_categorical_accuracy: 0.0388 - factorized_top_k/top_50_categorical_accuracy: 0.1542 - factorized_top_k/top_100_categorical_accuracy: 0.2757 - loss: 6821.2300 - regularization_loss: 0.0000e+00 - total_loss: 6821.2300\n",
      "Epoch 13/300\n",
      "40/40 [==============================] - 12s 227ms/step - root_mean_squared_error: 1.0241 - factorized_top_k/top_1_categorical_accuracy: 0.0041 - factorized_top_k/top_5_categorical_accuracy: 0.0193 - factorized_top_k/top_10_categorical_accuracy: 0.0368 - factorized_top_k/top_50_categorical_accuracy: 0.1569 - factorized_top_k/top_100_categorical_accuracy: 0.2831 - loss: 6801.4530 - regularization_loss: 0.0000e+00 - total_loss: 6801.4530\n",
      "Epoch 14/300\n",
      "40/40 [==============================] - 12s 218ms/step - root_mean_squared_error: 1.0142 - factorized_top_k/top_1_categorical_accuracy: 0.0052 - factorized_top_k/top_5_categorical_accuracy: 0.0212 - factorized_top_k/top_10_categorical_accuracy: 0.0394 - factorized_top_k/top_50_categorical_accuracy: 0.1637 - factorized_top_k/top_100_categorical_accuracy: 0.2928 - loss: 6789.0899 - regularization_loss: 0.0000e+00 - total_loss: 6789.0899\n",
      "Epoch 15/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 1.0143 - factorized_top_k/top_1_categorical_accuracy: 0.0046 - factorized_top_k/top_5_categorical_accuracy: 0.0217 - factorized_top_k/top_10_categorical_accuracy: 0.0402 - factorized_top_k/top_50_categorical_accuracy: 0.1695 - factorized_top_k/top_100_categorical_accuracy: 0.2996 - loss: 6939.7103 - regularization_loss: 0.0000e+00 - total_loss: 6939.7103\n",
      "Saved checkpoint to cp-014_loss-13929_acc100-0.2515_rmse-1.0603.ckpt\n",
      "40/40 [==============================] - 14s 258ms/step - root_mean_squared_error: 1.0143 - factorized_top_k/top_1_categorical_accuracy: 0.0046 - factorized_top_k/top_5_categorical_accuracy: 0.0217 - factorized_top_k/top_10_categorical_accuracy: 0.0402 - factorized_top_k/top_50_categorical_accuracy: 0.1695 - factorized_top_k/top_100_categorical_accuracy: 0.2996 - loss: 6776.8662 - regularization_loss: 0.0000e+00 - total_loss: 6776.8662 - val_root_mean_squared_error: 1.0603 - val_factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0083 - val_factorized_top_k/top_10_categorical_accuracy: 0.0200 - val_factorized_top_k/top_50_categorical_accuracy: 0.1265 - val_factorized_top_k/top_100_categorical_accuracy: 0.2515 - val_loss: 13929.3564 - val_regularization_loss: 0.0000e+00 - val_total_loss: 13929.3564\n",
      "Epoch 16/300\n",
      "40/40 [==============================] - 12s 223ms/step - root_mean_squared_error: 1.0130 - factorized_top_k/top_1_categorical_accuracy: 0.0030 - factorized_top_k/top_5_categorical_accuracy: 0.0199 - factorized_top_k/top_10_categorical_accuracy: 0.0388 - factorized_top_k/top_50_categorical_accuracy: 0.1704 - factorized_top_k/top_100_categorical_accuracy: 0.3061 - loss: 6760.2979 - regularization_loss: 0.0000e+00 - total_loss: 6760.2979\n",
      "Epoch 17/300\n",
      "40/40 [==============================] - 12s 220ms/step - root_mean_squared_error: 1.0129 - factorized_top_k/top_1_categorical_accuracy: 0.0039 - factorized_top_k/top_5_categorical_accuracy: 0.0208 - factorized_top_k/top_10_categorical_accuracy: 0.0392 - factorized_top_k/top_50_categorical_accuracy: 0.1741 - factorized_top_k/top_100_categorical_accuracy: 0.3097 - loss: 6750.7057 - regularization_loss: 0.0000e+00 - total_loss: 6750.7057\n",
      "Epoch 18/300\n",
      "40/40 [==============================] - 14s 249ms/step - root_mean_squared_error: 0.9993 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0209 - factorized_top_k/top_10_categorical_accuracy: 0.0410 - factorized_top_k/top_50_categorical_accuracy: 0.1781 - factorized_top_k/top_100_categorical_accuracy: 0.3138 - loss: 6739.1660 - regularization_loss: 0.0000e+00 - total_loss: 6739.1660\n",
      "Epoch 19/300\n",
      "40/40 [==============================] - 11s 210ms/step - root_mean_squared_error: 1.0057 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0214 - factorized_top_k/top_10_categorical_accuracy: 0.0414 - factorized_top_k/top_50_categorical_accuracy: 0.1807 - factorized_top_k/top_100_categorical_accuracy: 0.3184 - loss: 6729.8264 - regularization_loss: 0.0000e+00 - total_loss: 6729.8264\n",
      "Epoch 20/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9973 - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0219 - factorized_top_k/top_10_categorical_accuracy: 0.0422 - factorized_top_k/top_50_categorical_accuracy: 0.1827 - factorized_top_k/top_100_categorical_accuracy: 0.3217 - loss: 6881.3868 - regularization_loss: 0.0000e+00 - total_loss: 6881.3868\n",
      "Saved checkpoint to cp-019_loss-13923_acc100-0.2602_rmse-1.0609.ckpt\n",
      "40/40 [==============================] - 13s 253ms/step - root_mean_squared_error: 0.9973 - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0219 - factorized_top_k/top_10_categorical_accuracy: 0.0422 - factorized_top_k/top_50_categorical_accuracy: 0.1827 - factorized_top_k/top_100_categorical_accuracy: 0.3217 - loss: 6719.8904 - regularization_loss: 0.0000e+00 - total_loss: 6719.8904 - val_root_mean_squared_error: 1.0609 - val_factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0079 - val_factorized_top_k/top_10_categorical_accuracy: 0.0190 - val_factorized_top_k/top_50_categorical_accuracy: 0.1289 - val_factorized_top_k/top_100_categorical_accuracy: 0.2602 - val_loss: 13923.3145 - val_regularization_loss: 0.0000e+00 - val_total_loss: 13923.3145\n",
      "Epoch 21/300\n",
      "40/40 [==============================] - 14s 224ms/step - root_mean_squared_error: 1.0077 - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0206 - factorized_top_k/top_10_categorical_accuracy: 0.0418 - factorized_top_k/top_50_categorical_accuracy: 0.1841 - factorized_top_k/top_100_categorical_accuracy: 0.3270 - loss: 6709.1600 - regularization_loss: 0.0000e+00 - total_loss: 6709.1600\n",
      "Epoch 22/300\n",
      "40/40 [==============================] - 13s 233ms/step - root_mean_squared_error: 0.9942 - factorized_top_k/top_1_categorical_accuracy: 0.0038 - factorized_top_k/top_5_categorical_accuracy: 0.0222 - factorized_top_k/top_10_categorical_accuracy: 0.0431 - factorized_top_k/top_50_categorical_accuracy: 0.1887 - factorized_top_k/top_100_categorical_accuracy: 0.3300 - loss: 6701.5435 - regularization_loss: 0.0000e+00 - total_loss: 6701.5435\n",
      "Epoch 23/300\n",
      "40/40 [==============================] - 12s 214ms/step - root_mean_squared_error: 0.9966 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0216 - factorized_top_k/top_10_categorical_accuracy: 0.0436 - factorized_top_k/top_50_categorical_accuracy: 0.1910 - factorized_top_k/top_100_categorical_accuracy: 0.3336 - loss: 6693.0046 - regularization_loss: 0.0000e+00 - total_loss: 6693.0046\n",
      "Epoch 24/300\n",
      "40/40 [==============================] - 12s 227ms/step - root_mean_squared_error: 0.9910 - factorized_top_k/top_1_categorical_accuracy: 0.0029 - factorized_top_k/top_5_categorical_accuracy: 0.0212 - factorized_top_k/top_10_categorical_accuracy: 0.0432 - factorized_top_k/top_50_categorical_accuracy: 0.1916 - factorized_top_k/top_100_categorical_accuracy: 0.3369 - loss: 6686.2244 - regularization_loss: 0.0000e+00 - total_loss: 6686.2244\n",
      "Epoch 25/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9968 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0225 - factorized_top_k/top_10_categorical_accuracy: 0.0453 - factorized_top_k/top_50_categorical_accuracy: 0.1959 - factorized_top_k/top_100_categorical_accuracy: 0.3406 - loss: 6837.7760 - regularization_loss: 0.0000e+00 - total_loss: 6837.7760\n",
      "Saved checkpoint to cp-024_loss-13951_acc100-0.2539_rmse-0.9992.ckpt\n",
      "40/40 [==============================] - 13s 260ms/step - root_mean_squared_error: 0.9968 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0225 - factorized_top_k/top_10_categorical_accuracy: 0.0453 - factorized_top_k/top_50_categorical_accuracy: 0.1959 - factorized_top_k/top_100_categorical_accuracy: 0.3406 - loss: 6677.4501 - regularization_loss: 0.0000e+00 - total_loss: 6677.4501 - val_root_mean_squared_error: 0.9992 - val_factorized_top_k/top_1_categorical_accuracy: 8.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0062 - val_factorized_top_k/top_10_categorical_accuracy: 0.0169 - val_factorized_top_k/top_50_categorical_accuracy: 0.1217 - val_factorized_top_k/top_100_categorical_accuracy: 0.2539 - val_loss: 13951.2002 - val_regularization_loss: 0.0000e+00 - val_total_loss: 13951.2002\n",
      "Epoch 26/300\n",
      "40/40 [==============================] - 12s 226ms/step - root_mean_squared_error: 0.9923 - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0227 - factorized_top_k/top_10_categorical_accuracy: 0.0449 - factorized_top_k/top_50_categorical_accuracy: 0.1975 - factorized_top_k/top_100_categorical_accuracy: 0.3432 - loss: 6670.3439 - regularization_loss: 0.0000e+00 - total_loss: 6670.3439\n",
      "Epoch 27/300\n",
      "40/40 [==============================] - 13s 228ms/step - root_mean_squared_error: 0.9932 - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0241 - factorized_top_k/top_10_categorical_accuracy: 0.0467 - factorized_top_k/top_50_categorical_accuracy: 0.2004 - factorized_top_k/top_100_categorical_accuracy: 0.3471 - loss: 6664.5192 - regularization_loss: 0.0000e+00 - total_loss: 6664.5192\n",
      "Epoch 28/300\n",
      "40/40 [==============================] - 13s 227ms/step - root_mean_squared_error: 0.9890 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0239 - factorized_top_k/top_10_categorical_accuracy: 0.0471 - factorized_top_k/top_50_categorical_accuracy: 0.2014 - factorized_top_k/top_100_categorical_accuracy: 0.3489 - loss: 6658.5475 - regularization_loss: 0.0000e+00 - total_loss: 6658.5475\n",
      "Epoch 29/300\n",
      "40/40 [==============================] - 12s 216ms/step - root_mean_squared_error: 0.9879 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0239 - factorized_top_k/top_10_categorical_accuracy: 0.0472 - factorized_top_k/top_50_categorical_accuracy: 0.2042 - factorized_top_k/top_100_categorical_accuracy: 0.3499 - loss: 6652.3172 - regularization_loss: 0.0000e+00 - total_loss: 6652.3172\n",
      "Epoch 30/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9899 - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0249 - factorized_top_k/top_10_categorical_accuracy: 0.0487 - factorized_top_k/top_50_categorical_accuracy: 0.2061 - factorized_top_k/top_100_categorical_accuracy: 0.3544 - loss: 6805.5311 - regularization_loss: 0.0000e+00 - total_loss: 6805.5311\n",
      "Saved checkpoint to cp-029_loss-13971_acc100-0.2668_rmse-1.0057.ckpt\n",
      "40/40 [==============================] - 13s 252ms/step - root_mean_squared_error: 0.9899 - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0249 - factorized_top_k/top_10_categorical_accuracy: 0.0487 - factorized_top_k/top_50_categorical_accuracy: 0.2061 - factorized_top_k/top_100_categorical_accuracy: 0.3544 - loss: 6645.9915 - regularization_loss: 0.0000e+00 - total_loss: 6645.9915 - val_root_mean_squared_error: 1.0057 - val_factorized_top_k/top_1_categorical_accuracy: 6.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0069 - val_factorized_top_k/top_10_categorical_accuracy: 0.0181 - val_factorized_top_k/top_50_categorical_accuracy: 0.1304 - val_factorized_top_k/top_100_categorical_accuracy: 0.2668 - val_loss: 13970.6045 - val_regularization_loss: 0.0000e+00 - val_total_loss: 13970.6045\n",
      "Epoch 31/300\n",
      "40/40 [==============================] - 12s 225ms/step - root_mean_squared_error: 0.9820 - factorized_top_k/top_1_categorical_accuracy: 0.0039 - factorized_top_k/top_5_categorical_accuracy: 0.0258 - factorized_top_k/top_10_categorical_accuracy: 0.0501 - factorized_top_k/top_50_categorical_accuracy: 0.2078 - factorized_top_k/top_100_categorical_accuracy: 0.3554 - loss: 6641.6079 - regularization_loss: 0.0000e+00 - total_loss: 6641.6079\n",
      "Epoch 32/300\n",
      "40/40 [==============================] - 12s 218ms/step - root_mean_squared_error: 0.9801 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0250 - factorized_top_k/top_10_categorical_accuracy: 0.0492 - factorized_top_k/top_50_categorical_accuracy: 0.2096 - factorized_top_k/top_100_categorical_accuracy: 0.3584 - loss: 6634.5823 - regularization_loss: 0.0000e+00 - total_loss: 6634.5823\n",
      "Epoch 33/300\n",
      "40/40 [==============================] - 12s 218ms/step - root_mean_squared_error: 0.9886 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0258 - factorized_top_k/top_10_categorical_accuracy: 0.0505 - factorized_top_k/top_50_categorical_accuracy: 0.2127 - factorized_top_k/top_100_categorical_accuracy: 0.3628 - loss: 6629.2800 - regularization_loss: 0.0000e+00 - total_loss: 6629.2800\n",
      "Epoch 34/300\n",
      "40/40 [==============================] - 12s 218ms/step - root_mean_squared_error: 0.9806 - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0259 - factorized_top_k/top_10_categorical_accuracy: 0.0506 - factorized_top_k/top_50_categorical_accuracy: 0.2131 - factorized_top_k/top_100_categorical_accuracy: 0.3643 - loss: 6624.7974 - regularization_loss: 0.0000e+00 - total_loss: 6624.7974\n",
      "Epoch 35/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9811 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0258 - factorized_top_k/top_10_categorical_accuracy: 0.0505 - factorized_top_k/top_50_categorical_accuracy: 0.2157 - factorized_top_k/top_100_categorical_accuracy: 0.3669 - loss: 6778.8852 - regularization_loss: 0.0000e+00 - total_loss: 6778.8852\n",
      "Saved checkpoint to cp-034_loss-14010_acc100-0.2738_rmse-1.0748.ckpt\n",
      "40/40 [==============================] - 13s 258ms/step - root_mean_squared_error: 0.9811 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0258 - factorized_top_k/top_10_categorical_accuracy: 0.0505 - factorized_top_k/top_50_categorical_accuracy: 0.2157 - factorized_top_k/top_100_categorical_accuracy: 0.3669 - loss: 6619.8389 - regularization_loss: 0.0000e+00 - total_loss: 6619.8389 - val_root_mean_squared_error: 1.0748 - val_factorized_top_k/top_1_categorical_accuracy: 7.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0068 - val_factorized_top_k/top_10_categorical_accuracy: 0.0169 - val_factorized_top_k/top_50_categorical_accuracy: 0.1338 - val_factorized_top_k/top_100_categorical_accuracy: 0.2738 - val_loss: 14010.3721 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14010.3721\n",
      "Epoch 36/300\n",
      "40/40 [==============================] - 12s 215ms/step - root_mean_squared_error: 0.9828 - factorized_top_k/top_1_categorical_accuracy: 0.0030 - factorized_top_k/top_5_categorical_accuracy: 0.0262 - factorized_top_k/top_10_categorical_accuracy: 0.0521 - factorized_top_k/top_50_categorical_accuracy: 0.2172 - factorized_top_k/top_100_categorical_accuracy: 0.3685 - loss: 6614.7707 - regularization_loss: 0.0000e+00 - total_loss: 6614.7707\n",
      "Epoch 37/300\n",
      "40/40 [==============================] - 12s 218ms/step - root_mean_squared_error: 0.9721 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0270 - factorized_top_k/top_10_categorical_accuracy: 0.0527 - factorized_top_k/top_50_categorical_accuracy: 0.2189 - factorized_top_k/top_100_categorical_accuracy: 0.3696 - loss: 6610.9801 - regularization_loss: 0.0000e+00 - total_loss: 6610.9801\n",
      "Epoch 38/300\n",
      "40/40 [==============================] - 13s 251ms/step - root_mean_squared_error: 0.9778 - factorized_top_k/top_1_categorical_accuracy: 0.0030 - factorized_top_k/top_5_categorical_accuracy: 0.0263 - factorized_top_k/top_10_categorical_accuracy: 0.0522 - factorized_top_k/top_50_categorical_accuracy: 0.2195 - factorized_top_k/top_100_categorical_accuracy: 0.3718 - loss: 6605.3226 - regularization_loss: 0.0000e+00 - total_loss: 6605.3226\n",
      "Epoch 39/300\n",
      "40/40 [==============================] - 27s 517ms/step - root_mean_squared_error: 0.9737 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0271 - factorized_top_k/top_10_categorical_accuracy: 0.0519 - factorized_top_k/top_50_categorical_accuracy: 0.2208 - factorized_top_k/top_100_categorical_accuracy: 0.3734 - loss: 6602.2607 - regularization_loss: 0.0000e+00 - total_loss: 6602.2607\n",
      "Epoch 40/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9712 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0274 - factorized_top_k/top_10_categorical_accuracy: 0.0540 - factorized_top_k/top_50_categorical_accuracy: 0.2228 - factorized_top_k/top_100_categorical_accuracy: 0.3764 - loss: 6755.5195 - regularization_loss: 0.0000e+00 - total_loss: 6755.5195\n",
      "Saved checkpoint to cp-039_loss-14049_acc100-0.2677_rmse-1.0395.ckpt\n",
      "40/40 [==============================] - 15s 271ms/step - root_mean_squared_error: 0.9712 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0274 - factorized_top_k/top_10_categorical_accuracy: 0.0540 - factorized_top_k/top_50_categorical_accuracy: 0.2228 - factorized_top_k/top_100_categorical_accuracy: 0.3764 - loss: 6597.0969 - regularization_loss: 0.0000e+00 - total_loss: 6597.0969 - val_root_mean_squared_error: 1.0395 - val_factorized_top_k/top_1_categorical_accuracy: 5.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0060 - val_factorized_top_k/top_10_categorical_accuracy: 0.0162 - val_factorized_top_k/top_50_categorical_accuracy: 0.1286 - val_factorized_top_k/top_100_categorical_accuracy: 0.2677 - val_loss: 14049.0449 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14049.0449\n",
      "Epoch 41/300\n",
      "40/40 [==============================] - 12s 211ms/step - root_mean_squared_error: 0.9800 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0280 - factorized_top_k/top_10_categorical_accuracy: 0.0549 - factorized_top_k/top_50_categorical_accuracy: 0.2251 - factorized_top_k/top_100_categorical_accuracy: 0.3778 - loss: 6593.7860 - regularization_loss: 0.0000e+00 - total_loss: 6593.7860\n",
      "Epoch 42/300\n",
      "40/40 [==============================] - 12s 226ms/step - root_mean_squared_error: 0.9747 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0280 - factorized_top_k/top_10_categorical_accuracy: 0.0551 - factorized_top_k/top_50_categorical_accuracy: 0.2253 - factorized_top_k/top_100_categorical_accuracy: 0.3792 - loss: 6590.1650 - regularization_loss: 0.0000e+00 - total_loss: 6590.1650\n",
      "Epoch 43/300\n",
      "40/40 [==============================] - 13s 230ms/step - root_mean_squared_error: 0.9744 - factorized_top_k/top_1_categorical_accuracy: 0.0027 - factorized_top_k/top_5_categorical_accuracy: 0.0279 - factorized_top_k/top_10_categorical_accuracy: 0.0546 - factorized_top_k/top_50_categorical_accuracy: 0.2261 - factorized_top_k/top_100_categorical_accuracy: 0.3806 - loss: 6584.9280 - regularization_loss: 0.0000e+00 - total_loss: 6584.9280\n",
      "Epoch 44/300\n",
      "40/40 [==============================] - 13s 243ms/step - root_mean_squared_error: 0.9654 - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0286 - factorized_top_k/top_10_categorical_accuracy: 0.0562 - factorized_top_k/top_50_categorical_accuracy: 0.2288 - factorized_top_k/top_100_categorical_accuracy: 0.3834 - loss: 6583.0370 - regularization_loss: 0.0000e+00 - total_loss: 6583.0370\n",
      "Epoch 45/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9739 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0288 - factorized_top_k/top_10_categorical_accuracy: 0.0556 - factorized_top_k/top_50_categorical_accuracy: 0.2308 - factorized_top_k/top_100_categorical_accuracy: 0.3848 - loss: 6735.8531 - regularization_loss: 0.0000e+00 - total_loss: 6735.8531\n",
      "Saved checkpoint to cp-044_loss-14068_acc100-0.2749_rmse-1.0072.ckpt\n",
      "40/40 [==============================] - 14s 287ms/step - root_mean_squared_error: 0.9739 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0288 - factorized_top_k/top_10_categorical_accuracy: 0.0556 - factorized_top_k/top_50_categorical_accuracy: 0.2308 - factorized_top_k/top_100_categorical_accuracy: 0.3848 - loss: 6577.9726 - regularization_loss: 0.0000e+00 - total_loss: 6577.9726 - val_root_mean_squared_error: 1.0072 - val_factorized_top_k/top_1_categorical_accuracy: 6.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0054 - val_factorized_top_k/top_10_categorical_accuracy: 0.0154 - val_factorized_top_k/top_50_categorical_accuracy: 0.1327 - val_factorized_top_k/top_100_categorical_accuracy: 0.2749 - val_loss: 14068.4961 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14068.4961\n",
      "Epoch 46/300\n",
      "40/40 [==============================] - 13s 244ms/step - root_mean_squared_error: 0.9661 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0289 - factorized_top_k/top_10_categorical_accuracy: 0.0567 - factorized_top_k/top_50_categorical_accuracy: 0.2314 - factorized_top_k/top_100_categorical_accuracy: 0.3859 - loss: 6575.1316 - regularization_loss: 0.0000e+00 - total_loss: 6575.1316\n",
      "Epoch 47/300\n",
      "40/40 [==============================] - 12s 222ms/step - root_mean_squared_error: 0.9720 - factorized_top_k/top_1_categorical_accuracy: 0.0037 - factorized_top_k/top_5_categorical_accuracy: 0.0297 - factorized_top_k/top_10_categorical_accuracy: 0.0580 - factorized_top_k/top_50_categorical_accuracy: 0.2323 - factorized_top_k/top_100_categorical_accuracy: 0.3888 - loss: 6572.4558 - regularization_loss: 0.0000e+00 - total_loss: 6572.4558\n",
      "Epoch 48/300\n",
      "40/40 [==============================] - 13s 253ms/step - root_mean_squared_error: 0.9644 - factorized_top_k/top_1_categorical_accuracy: 0.0029 - factorized_top_k/top_5_categorical_accuracy: 0.0294 - factorized_top_k/top_10_categorical_accuracy: 0.0583 - factorized_top_k/top_50_categorical_accuracy: 0.2343 - factorized_top_k/top_100_categorical_accuracy: 0.3893 - loss: 6567.4193 - regularization_loss: 0.0000e+00 - total_loss: 6567.4193\n",
      "Epoch 49/300\n",
      "40/40 [==============================] - 12s 222ms/step - root_mean_squared_error: 0.9660 - factorized_top_k/top_1_categorical_accuracy: 0.0030 - factorized_top_k/top_5_categorical_accuracy: 0.0297 - factorized_top_k/top_10_categorical_accuracy: 0.0586 - factorized_top_k/top_50_categorical_accuracy: 0.2353 - factorized_top_k/top_100_categorical_accuracy: 0.3916 - loss: 6566.2003 - regularization_loss: 0.0000e+00 - total_loss: 6566.2003\n",
      "Epoch 50/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9628 - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0309 - factorized_top_k/top_10_categorical_accuracy: 0.0595 - factorized_top_k/top_50_categorical_accuracy: 0.2362 - factorized_top_k/top_100_categorical_accuracy: 0.3930 - loss: 6719.5883 - regularization_loss: 0.0000e+00 - total_loss: 6719.5883\n",
      "Saved checkpoint to cp-049_loss-14131_acc100-0.2723_rmse-0.9870.ckpt\n",
      "40/40 [==============================] - 13s 242ms/step - root_mean_squared_error: 0.9628 - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0309 - factorized_top_k/top_10_categorical_accuracy: 0.0595 - factorized_top_k/top_50_categorical_accuracy: 0.2362 - factorized_top_k/top_100_categorical_accuracy: 0.3930 - loss: 6561.7569 - regularization_loss: 0.0000e+00 - total_loss: 6561.7569 - val_root_mean_squared_error: 0.9870 - val_factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0055 - val_factorized_top_k/top_10_categorical_accuracy: 0.0152 - val_factorized_top_k/top_50_categorical_accuracy: 0.1295 - val_factorized_top_k/top_100_categorical_accuracy: 0.2723 - val_loss: 14130.8809 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14130.8809\n",
      "Epoch 51/300\n",
      "40/40 [==============================] - 11s 214ms/step - root_mean_squared_error: 0.9587 - factorized_top_k/top_1_categorical_accuracy: 0.0038 - factorized_top_k/top_5_categorical_accuracy: 0.0309 - factorized_top_k/top_10_categorical_accuracy: 0.0604 - factorized_top_k/top_50_categorical_accuracy: 0.2377 - factorized_top_k/top_100_categorical_accuracy: 0.3940 - loss: 6559.6868 - regularization_loss: 0.0000e+00 - total_loss: 6559.6868\n",
      "Epoch 52/300\n",
      "40/40 [==============================] - 13s 240ms/step - root_mean_squared_error: 0.9670 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0312 - factorized_top_k/top_10_categorical_accuracy: 0.0598 - factorized_top_k/top_50_categorical_accuracy: 0.2384 - factorized_top_k/top_100_categorical_accuracy: 0.3940 - loss: 6555.1512 - regularization_loss: 0.0000e+00 - total_loss: 6555.1512\n",
      "Epoch 53/300\n",
      "40/40 [==============================] - 12s 218ms/step - root_mean_squared_error: 0.9663 - factorized_top_k/top_1_categorical_accuracy: 0.0037 - factorized_top_k/top_5_categorical_accuracy: 0.0313 - factorized_top_k/top_10_categorical_accuracy: 0.0600 - factorized_top_k/top_50_categorical_accuracy: 0.2404 - factorized_top_k/top_100_categorical_accuracy: 0.3962 - loss: 6554.3788 - regularization_loss: 0.0000e+00 - total_loss: 6554.3788\n",
      "Epoch 54/300\n",
      "40/40 [==============================] - 11s 211ms/step - root_mean_squared_error: 0.9633 - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0318 - factorized_top_k/top_10_categorical_accuracy: 0.0614 - factorized_top_k/top_50_categorical_accuracy: 0.2412 - factorized_top_k/top_100_categorical_accuracy: 0.3971 - loss: 6549.8104 - regularization_loss: 0.0000e+00 - total_loss: 6549.8104\n",
      "Epoch 55/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9644 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0326 - factorized_top_k/top_10_categorical_accuracy: 0.0624 - factorized_top_k/top_50_categorical_accuracy: 0.2419 - factorized_top_k/top_100_categorical_accuracy: 0.3984 - loss: 6704.9641 - regularization_loss: 0.0000e+00 - total_loss: 6704.9641\n",
      "Saved checkpoint to cp-054_loss-14154_acc100-0.2880_rmse-1.0282.ckpt\n",
      "40/40 [==============================] - 15s 304ms/step - root_mean_squared_error: 0.9644 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0326 - factorized_top_k/top_10_categorical_accuracy: 0.0624 - factorized_top_k/top_50_categorical_accuracy: 0.2419 - factorized_top_k/top_100_categorical_accuracy: 0.3984 - loss: 6547.7916 - regularization_loss: 0.0000e+00 - total_loss: 6547.7916 - val_root_mean_squared_error: 1.0282 - val_factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0067 - val_factorized_top_k/top_10_categorical_accuracy: 0.0175 - val_factorized_top_k/top_50_categorical_accuracy: 0.1426 - val_factorized_top_k/top_100_categorical_accuracy: 0.2880 - val_loss: 14153.8027 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14153.8027\n",
      "Epoch 56/300\n",
      "40/40 [==============================] - 12s 217ms/step - root_mean_squared_error: 0.9553 - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0321 - factorized_top_k/top_10_categorical_accuracy: 0.0619 - factorized_top_k/top_50_categorical_accuracy: 0.2433 - factorized_top_k/top_100_categorical_accuracy: 0.4000 - loss: 6544.5039 - regularization_loss: 0.0000e+00 - total_loss: 6544.5039\n",
      "Epoch 57/300\n",
      "40/40 [==============================] - 12s 217ms/step - root_mean_squared_error: 0.9571 - factorized_top_k/top_1_categorical_accuracy: 0.0037 - factorized_top_k/top_5_categorical_accuracy: 0.0331 - factorized_top_k/top_10_categorical_accuracy: 0.0635 - factorized_top_k/top_50_categorical_accuracy: 0.2449 - factorized_top_k/top_100_categorical_accuracy: 0.4009 - loss: 6542.0564 - regularization_loss: 0.0000e+00 - total_loss: 6542.0564\n",
      "Epoch 58/300\n",
      "40/40 [==============================] - 11s 212ms/step - root_mean_squared_error: 0.9534 - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0325 - factorized_top_k/top_10_categorical_accuracy: 0.0639 - factorized_top_k/top_50_categorical_accuracy: 0.2463 - factorized_top_k/top_100_categorical_accuracy: 0.4019 - loss: 6540.2068 - regularization_loss: 0.0000e+00 - total_loss: 6540.2068\n",
      "Epoch 59/300\n",
      "40/40 [==============================] - 11s 211ms/step - root_mean_squared_error: 0.9534 - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0333 - factorized_top_k/top_10_categorical_accuracy: 0.0636 - factorized_top_k/top_50_categorical_accuracy: 0.2462 - factorized_top_k/top_100_categorical_accuracy: 0.4038 - loss: 6537.7546 - regularization_loss: 0.0000e+00 - total_loss: 6537.7546\n",
      "Epoch 60/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9593 - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0333 - factorized_top_k/top_10_categorical_accuracy: 0.0647 - factorized_top_k/top_50_categorical_accuracy: 0.2470 - factorized_top_k/top_100_categorical_accuracy: 0.4044 - loss: 6691.9810 - regularization_loss: 0.0000e+00 - total_loss: 6691.9810\n",
      "Saved checkpoint to cp-059_loss-14189_acc100-0.2742_rmse-1.0056.ckpt\n",
      "40/40 [==============================] - 13s 252ms/step - root_mean_squared_error: 0.9593 - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0333 - factorized_top_k/top_10_categorical_accuracy: 0.0647 - factorized_top_k/top_50_categorical_accuracy: 0.2470 - factorized_top_k/top_100_categorical_accuracy: 0.4044 - loss: 6535.0217 - regularization_loss: 0.0000e+00 - total_loss: 6535.0217 - val_root_mean_squared_error: 1.0056 - val_factorized_top_k/top_1_categorical_accuracy: 2.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0055 - val_factorized_top_k/top_10_categorical_accuracy: 0.0161 - val_factorized_top_k/top_50_categorical_accuracy: 0.1318 - val_factorized_top_k/top_100_categorical_accuracy: 0.2742 - val_loss: 14188.9932 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14188.9932\n",
      "Epoch 61/300\n",
      "40/40 [==============================] - 12s 221ms/step - root_mean_squared_error: 0.9505 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0340 - factorized_top_k/top_10_categorical_accuracy: 0.0649 - factorized_top_k/top_50_categorical_accuracy: 0.2486 - factorized_top_k/top_100_categorical_accuracy: 0.4054 - loss: 6532.3950 - regularization_loss: 0.0000e+00 - total_loss: 6532.3950\n",
      "Epoch 62/300\n",
      "40/40 [==============================] - 12s 224ms/step - root_mean_squared_error: 0.9540 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0338 - factorized_top_k/top_10_categorical_accuracy: 0.0645 - factorized_top_k/top_50_categorical_accuracy: 0.2477 - factorized_top_k/top_100_categorical_accuracy: 0.4060 - loss: 6530.5229 - regularization_loss: 0.0000e+00 - total_loss: 6530.5229\n",
      "Epoch 63/300\n",
      "40/40 [==============================] - 12s 230ms/step - root_mean_squared_error: 0.9485 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0334 - factorized_top_k/top_10_categorical_accuracy: 0.0653 - factorized_top_k/top_50_categorical_accuracy: 0.2489 - factorized_top_k/top_100_categorical_accuracy: 0.4061 - loss: 6528.1353 - regularization_loss: 0.0000e+00 - total_loss: 6528.1353\n",
      "Epoch 64/300\n",
      "40/40 [==============================] - 12s 228ms/step - root_mean_squared_error: 0.9464 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0349 - factorized_top_k/top_10_categorical_accuracy: 0.0656 - factorized_top_k/top_50_categorical_accuracy: 0.2510 - factorized_top_k/top_100_categorical_accuracy: 0.4081 - loss: 6525.5030 - regularization_loss: 0.0000e+00 - total_loss: 6525.5030\n",
      "Epoch 65/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9511 - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0348 - factorized_top_k/top_10_categorical_accuracy: 0.0662 - factorized_top_k/top_50_categorical_accuracy: 0.2512 - factorized_top_k/top_100_categorical_accuracy: 0.4086 - loss: 6679.5127 - regularization_loss: 0.0000e+00 - total_loss: 6679.5127\n",
      "Saved checkpoint to cp-064_loss-14216_acc100-0.2819_rmse-0.9902.ckpt\n",
      "40/40 [==============================] - 13s 253ms/step - root_mean_squared_error: 0.9511 - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0348 - factorized_top_k/top_10_categorical_accuracy: 0.0662 - factorized_top_k/top_50_categorical_accuracy: 0.2512 - factorized_top_k/top_100_categorical_accuracy: 0.4086 - loss: 6522.7372 - regularization_loss: 0.0000e+00 - total_loss: 6522.7372 - val_root_mean_squared_error: 0.9902 - val_factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0057 - val_factorized_top_k/top_10_categorical_accuracy: 0.0159 - val_factorized_top_k/top_50_categorical_accuracy: 0.1340 - val_factorized_top_k/top_100_categorical_accuracy: 0.2819 - val_loss: 14216.3896 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14216.3896\n",
      "Epoch 66/300\n",
      "40/40 [==============================] - 12s 215ms/step - root_mean_squared_error: 0.9529 - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0354 - factorized_top_k/top_10_categorical_accuracy: 0.0657 - factorized_top_k/top_50_categorical_accuracy: 0.2514 - factorized_top_k/top_100_categorical_accuracy: 0.4095 - loss: 6520.9905 - regularization_loss: 0.0000e+00 - total_loss: 6520.9905\n",
      "Epoch 67/300\n",
      "40/40 [==============================] - 12s 226ms/step - root_mean_squared_error: 0.9484 - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0347 - factorized_top_k/top_10_categorical_accuracy: 0.0673 - factorized_top_k/top_50_categorical_accuracy: 0.2537 - factorized_top_k/top_100_categorical_accuracy: 0.4112 - loss: 6519.6267 - regularization_loss: 0.0000e+00 - total_loss: 6519.6267\n",
      "Epoch 68/300\n",
      "40/40 [==============================] - 12s 227ms/step - root_mean_squared_error: 0.9417 - factorized_top_k/top_1_categorical_accuracy: 0.0037 - factorized_top_k/top_5_categorical_accuracy: 0.0357 - factorized_top_k/top_10_categorical_accuracy: 0.0679 - factorized_top_k/top_50_categorical_accuracy: 0.2534 - factorized_top_k/top_100_categorical_accuracy: 0.4113 - loss: 6518.9138 - regularization_loss: 0.0000e+00 - total_loss: 6518.9138\n",
      "Epoch 69/300\n",
      "40/40 [==============================] - 12s 213ms/step - root_mean_squared_error: 0.9464 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0350 - factorized_top_k/top_10_categorical_accuracy: 0.0671 - factorized_top_k/top_50_categorical_accuracy: 0.2523 - factorized_top_k/top_100_categorical_accuracy: 0.4125 - loss: 6516.1048 - regularization_loss: 0.0000e+00 - total_loss: 6516.1048\n",
      "Epoch 70/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9480 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0356 - factorized_top_k/top_10_categorical_accuracy: 0.0678 - factorized_top_k/top_50_categorical_accuracy: 0.2547 - factorized_top_k/top_100_categorical_accuracy: 0.4128 - loss: 6669.9820 - regularization_loss: 0.0000e+00 - total_loss: 6669.9820\n",
      "Saved checkpoint to cp-069_loss-14263_acc100-0.2842_rmse-1.0535.ckpt\n",
      "40/40 [==============================] - 13s 249ms/step - root_mean_squared_error: 0.9480 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0356 - factorized_top_k/top_10_categorical_accuracy: 0.0678 - factorized_top_k/top_50_categorical_accuracy: 0.2547 - factorized_top_k/top_100_categorical_accuracy: 0.4128 - loss: 6513.4907 - regularization_loss: 0.0000e+00 - total_loss: 6513.4907 - val_root_mean_squared_error: 1.0535 - val_factorized_top_k/top_1_categorical_accuracy: 3.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0060 - val_factorized_top_k/top_10_categorical_accuracy: 0.0166 - val_factorized_top_k/top_50_categorical_accuracy: 0.1381 - val_factorized_top_k/top_100_categorical_accuracy: 0.2842 - val_loss: 14263.2061 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14263.2061\n",
      "Epoch 71/300\n",
      "40/40 [==============================] - 12s 221ms/step - root_mean_squared_error: 0.9420 - factorized_top_k/top_1_categorical_accuracy: 0.0030 - factorized_top_k/top_5_categorical_accuracy: 0.0358 - factorized_top_k/top_10_categorical_accuracy: 0.0681 - factorized_top_k/top_50_categorical_accuracy: 0.2564 - factorized_top_k/top_100_categorical_accuracy: 0.4149 - loss: 6511.2037 - regularization_loss: 0.0000e+00 - total_loss: 6511.2037\n",
      "Epoch 72/300\n",
      "40/40 [==============================] - 12s 223ms/step - root_mean_squared_error: 0.9455 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0359 - factorized_top_k/top_10_categorical_accuracy: 0.0682 - factorized_top_k/top_50_categorical_accuracy: 0.2566 - factorized_top_k/top_100_categorical_accuracy: 0.4150 - loss: 6508.6323 - regularization_loss: 0.0000e+00 - total_loss: 6508.6323\n",
      "Epoch 73/300\n",
      "40/40 [==============================] - 12s 214ms/step - root_mean_squared_error: 0.9404 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0361 - factorized_top_k/top_10_categorical_accuracy: 0.0684 - factorized_top_k/top_50_categorical_accuracy: 0.2566 - factorized_top_k/top_100_categorical_accuracy: 0.4152 - loss: 6507.3107 - regularization_loss: 0.0000e+00 - total_loss: 6507.3107\n",
      "Epoch 74/300\n",
      "40/40 [==============================] - 12s 225ms/step - root_mean_squared_error: 0.9360 - factorized_top_k/top_1_categorical_accuracy: 0.0039 - factorized_top_k/top_5_categorical_accuracy: 0.0368 - factorized_top_k/top_10_categorical_accuracy: 0.0693 - factorized_top_k/top_50_categorical_accuracy: 0.2584 - factorized_top_k/top_100_categorical_accuracy: 0.4173 - loss: 6505.4019 - regularization_loss: 0.0000e+00 - total_loss: 6505.4019\n",
      "Epoch 75/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9390 - factorized_top_k/top_1_categorical_accuracy: 0.0040 - factorized_top_k/top_5_categorical_accuracy: 0.0375 - factorized_top_k/top_10_categorical_accuracy: 0.0696 - factorized_top_k/top_50_categorical_accuracy: 0.2575 - factorized_top_k/top_100_categorical_accuracy: 0.4177 - loss: 6660.9807 - regularization_loss: 0.0000e+00 - total_loss: 6660.9807\n",
      "Saved checkpoint to cp-074_loss-14294_acc100-0.2859_rmse-0.9763.ckpt\n",
      "40/40 [==============================] - 13s 251ms/step - root_mean_squared_error: 0.9390 - factorized_top_k/top_1_categorical_accuracy: 0.0040 - factorized_top_k/top_5_categorical_accuracy: 0.0375 - factorized_top_k/top_10_categorical_accuracy: 0.0696 - factorized_top_k/top_50_categorical_accuracy: 0.2575 - factorized_top_k/top_100_categorical_accuracy: 0.4177 - loss: 6504.6219 - regularization_loss: 0.0000e+00 - total_loss: 6504.6219 - val_root_mean_squared_error: 0.9763 - val_factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0047 - val_factorized_top_k/top_10_categorical_accuracy: 0.0148 - val_factorized_top_k/top_50_categorical_accuracy: 0.1356 - val_factorized_top_k/top_100_categorical_accuracy: 0.2859 - val_loss: 14293.9639 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14293.9639\n",
      "Epoch 76/300\n",
      "40/40 [==============================] - 12s 223ms/step - root_mean_squared_error: 0.9405 - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0370 - factorized_top_k/top_10_categorical_accuracy: 0.0702 - factorized_top_k/top_50_categorical_accuracy: 0.2587 - factorized_top_k/top_100_categorical_accuracy: 0.4194 - loss: 6502.6407 - regularization_loss: 0.0000e+00 - total_loss: 6502.6407\n",
      "Epoch 77/300\n",
      "40/40 [==============================] - 11s 214ms/step - root_mean_squared_error: 0.9376 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0365 - factorized_top_k/top_10_categorical_accuracy: 0.0698 - factorized_top_k/top_50_categorical_accuracy: 0.2605 - factorized_top_k/top_100_categorical_accuracy: 0.4187 - loss: 6500.4431 - regularization_loss: 0.0000e+00 - total_loss: 6500.4431\n",
      "Epoch 78/300\n",
      "40/40 [==============================] - 12s 215ms/step - root_mean_squared_error: 0.9383 - factorized_top_k/top_1_categorical_accuracy: 0.0037 - factorized_top_k/top_5_categorical_accuracy: 0.0376 - factorized_top_k/top_10_categorical_accuracy: 0.0710 - factorized_top_k/top_50_categorical_accuracy: 0.2604 - factorized_top_k/top_100_categorical_accuracy: 0.4195 - loss: 6499.6817 - regularization_loss: 0.0000e+00 - total_loss: 6499.6817\n",
      "Epoch 79/300\n",
      "40/40 [==============================] - 12s 214ms/step - root_mean_squared_error: 0.9273 - factorized_top_k/top_1_categorical_accuracy: 0.0038 - factorized_top_k/top_5_categorical_accuracy: 0.0372 - factorized_top_k/top_10_categorical_accuracy: 0.0716 - factorized_top_k/top_50_categorical_accuracy: 0.2599 - factorized_top_k/top_100_categorical_accuracy: 0.4212 - loss: 6497.6291 - regularization_loss: 0.0000e+00 - total_loss: 6497.6291\n",
      "Epoch 80/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9417 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0371 - factorized_top_k/top_10_categorical_accuracy: 0.0705 - factorized_top_k/top_50_categorical_accuracy: 0.2610 - factorized_top_k/top_100_categorical_accuracy: 0.4204 - loss: 6651.8280 - regularization_loss: 0.0000e+00 - total_loss: 6651.8280\n",
      "Saved checkpoint to cp-079_loss-14326_acc100-0.2795_rmse-1.0186.ckpt\n",
      "40/40 [==============================] - 13s 246ms/step - root_mean_squared_error: 0.9417 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0371 - factorized_top_k/top_10_categorical_accuracy: 0.0705 - factorized_top_k/top_50_categorical_accuracy: 0.2610 - factorized_top_k/top_100_categorical_accuracy: 0.4204 - loss: 6495.8631 - regularization_loss: 0.0000e+00 - total_loss: 6495.8631 - val_root_mean_squared_error: 1.0186 - val_factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0049 - val_factorized_top_k/top_10_categorical_accuracy: 0.0143 - val_factorized_top_k/top_50_categorical_accuracy: 0.1333 - val_factorized_top_k/top_100_categorical_accuracy: 0.2795 - val_loss: 14326.1016 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14326.1016\n",
      "Epoch 81/300\n",
      "40/40 [==============================] - 11s 212ms/step - root_mean_squared_error: 0.9344 - factorized_top_k/top_1_categorical_accuracy: 0.0044 - factorized_top_k/top_5_categorical_accuracy: 0.0381 - factorized_top_k/top_10_categorical_accuracy: 0.0715 - factorized_top_k/top_50_categorical_accuracy: 0.2617 - factorized_top_k/top_100_categorical_accuracy: 0.4212 - loss: 6494.2520 - regularization_loss: 0.0000e+00 - total_loss: 6494.2520\n",
      "Epoch 82/300\n",
      "40/40 [==============================] - 12s 213ms/step - root_mean_squared_error: 0.9331 - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0383 - factorized_top_k/top_10_categorical_accuracy: 0.0718 - factorized_top_k/top_50_categorical_accuracy: 0.2619 - factorized_top_k/top_100_categorical_accuracy: 0.4232 - loss: 6492.9418 - regularization_loss: 0.0000e+00 - total_loss: 6492.9418\n",
      "Epoch 83/300\n",
      "40/40 [==============================] - 11s 212ms/step - root_mean_squared_error: 0.9286 - factorized_top_k/top_1_categorical_accuracy: 0.0039 - factorized_top_k/top_5_categorical_accuracy: 0.0382 - factorized_top_k/top_10_categorical_accuracy: 0.0719 - factorized_top_k/top_50_categorical_accuracy: 0.2634 - factorized_top_k/top_100_categorical_accuracy: 0.4224 - loss: 6491.2961 - regularization_loss: 0.0000e+00 - total_loss: 6491.2961\n",
      "Epoch 84/300\n",
      "40/40 [==============================] - 12s 228ms/step - root_mean_squared_error: 0.9329 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0385 - factorized_top_k/top_10_categorical_accuracy: 0.0717 - factorized_top_k/top_50_categorical_accuracy: 0.2637 - factorized_top_k/top_100_categorical_accuracy: 0.4227 - loss: 6489.6367 - regularization_loss: 0.0000e+00 - total_loss: 6489.6367\n",
      "Epoch 85/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9287 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0385 - factorized_top_k/top_10_categorical_accuracy: 0.0721 - factorized_top_k/top_50_categorical_accuracy: 0.2649 - factorized_top_k/top_100_categorical_accuracy: 0.4246 - loss: 6644.0156 - regularization_loss: 0.0000e+00 - total_loss: 6644.0156\n",
      "Saved checkpoint to cp-084_loss-14374_acc100-0.2833_rmse-1.0312.ckpt\n",
      "40/40 [==============================] - 13s 258ms/step - root_mean_squared_error: 0.9287 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0385 - factorized_top_k/top_10_categorical_accuracy: 0.0721 - factorized_top_k/top_50_categorical_accuracy: 0.2649 - factorized_top_k/top_100_categorical_accuracy: 0.4246 - loss: 6488.2354 - regularization_loss: 0.0000e+00 - total_loss: 6488.2354 - val_root_mean_squared_error: 1.0312 - val_factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0048 - val_factorized_top_k/top_10_categorical_accuracy: 0.0150 - val_factorized_top_k/top_50_categorical_accuracy: 0.1362 - val_factorized_top_k/top_100_categorical_accuracy: 0.2833 - val_loss: 14373.6631 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14373.6631\n",
      "Epoch 86/300\n",
      "40/40 [==============================] - 12s 215ms/step - root_mean_squared_error: 0.9343 - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0385 - factorized_top_k/top_10_categorical_accuracy: 0.0719 - factorized_top_k/top_50_categorical_accuracy: 0.2655 - factorized_top_k/top_100_categorical_accuracy: 0.4255 - loss: 6486.9067 - regularization_loss: 0.0000e+00 - total_loss: 6486.9067\n",
      "Epoch 87/300\n",
      "40/40 [==============================] - 12s 214ms/step - root_mean_squared_error: 0.9255 - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0389 - factorized_top_k/top_10_categorical_accuracy: 0.0725 - factorized_top_k/top_50_categorical_accuracy: 0.2650 - factorized_top_k/top_100_categorical_accuracy: 0.4248 - loss: 6485.5476 - regularization_loss: 0.0000e+00 - total_loss: 6485.5476\n",
      "Epoch 88/300\n",
      "40/40 [==============================] - 13s 224ms/step - root_mean_squared_error: 0.9246 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0390 - factorized_top_k/top_10_categorical_accuracy: 0.0729 - factorized_top_k/top_50_categorical_accuracy: 0.2659 - factorized_top_k/top_100_categorical_accuracy: 0.4253 - loss: 6484.6745 - regularization_loss: 0.0000e+00 - total_loss: 6484.6745\n",
      "Epoch 89/300\n",
      "40/40 [==============================] - 12s 226ms/step - root_mean_squared_error: 0.9228 - factorized_top_k/top_1_categorical_accuracy: 0.0039 - factorized_top_k/top_5_categorical_accuracy: 0.0392 - factorized_top_k/top_10_categorical_accuracy: 0.0736 - factorized_top_k/top_50_categorical_accuracy: 0.2668 - factorized_top_k/top_100_categorical_accuracy: 0.4272 - loss: 6482.4754 - regularization_loss: 0.0000e+00 - total_loss: 6482.4754\n",
      "Epoch 90/300\n",
      "40/40 [==============================] - ETA: 0s - root_mean_squared_error: 0.9263 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0394 - factorized_top_k/top_10_categorical_accuracy: 0.0736 - factorized_top_k/top_50_categorical_accuracy: 0.2669 - factorized_top_k/top_100_categorical_accuracy: 0.4278 - loss: 6636.7766 - regularization_loss: 0.0000e+00 - total_loss: 6636.7766\n",
      "Saved checkpoint to cp-089_loss-14386_acc100-0.2860_rmse-1.0032.ckpt\n",
      "40/40 [==============================] - 13s 256ms/step - root_mean_squared_error: 0.9263 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0394 - factorized_top_k/top_10_categorical_accuracy: 0.0736 - factorized_top_k/top_50_categorical_accuracy: 0.2669 - factorized_top_k/top_100_categorical_accuracy: 0.4278 - loss: 6481.1489 - regularization_loss: 0.0000e+00 - total_loss: 6481.1489 - val_root_mean_squared_error: 1.0032 - val_factorized_top_k/top_1_categorical_accuracy: 3.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0049 - val_factorized_top_k/top_10_categorical_accuracy: 0.0151 - val_factorized_top_k/top_50_categorical_accuracy: 0.1380 - val_factorized_top_k/top_100_categorical_accuracy: 0.2860 - val_loss: 14386.1963 - val_regularization_loss: 0.0000e+00 - val_total_loss: 14386.1963\n",
      "Epoch 91/300\n",
      "40/40 [==============================] - 13s 240ms/step - root_mean_squared_error: 0.9190 - factorized_top_k/top_1_categorical_accuracy: 0.0042 - factorized_top_k/top_5_categorical_accuracy: 0.0392 - factorized_top_k/top_10_categorical_accuracy: 0.0743 - factorized_top_k/top_50_categorical_accuracy: 0.2676 - factorized_top_k/top_100_categorical_accuracy: 0.4275 - loss: 6479.6226 - regularization_loss: 0.0000e+00 - total_loss: 6479.6226\n",
      "Epoch 92/300\n",
      "10/40 [======>.......................] - ETA: 7s - root_mean_squared_error: 0.9117 - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0422 - factorized_top_k/top_10_categorical_accuracy: 0.0789 - factorized_top_k/top_50_categorical_accuracy: 0.2764 - factorized_top_k/top_100_categorical_accuracy: 0.4375 - loss: 6768.5312 - regularization_loss: 0.0000e+00 - total_loss: 6768.5312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m MovielensModel(\u001b[38;5;241m0.5\u001b[39m, [\u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m32\u001b[39m], [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m])\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdagrad(LR))\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcached_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_factorized_top_k/top_100_categorical_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m rmse \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_root_mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MovielensModel(0.5, [96, 32], [64, 32])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(LR))\n",
    "\n",
    "history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=EPOCHS, \n",
    "    callbacks=[cp_callback],\n",
    "    verbose=True)\n",
    "\n",
    "accuracy = history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "rmse = history.history[\"val_root_mean_squared_error\"][-1]\n",
    "print(f\"Top-100 accuracy: {accuracy:.2f}.\")\n",
    "print(f\"RMSE: {rmse:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_runs = len(history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"])\n",
    "epochs = [(x + 1)* 5 for x in range(num_validation_runs)]\n",
    "acc = history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"]\n",
    "rmse = history.history[\"val_root_mean_squared_error\"]\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('Top-100 accuracy', color=color)\n",
    "ax1.plot(epochs, acc, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('RMSE', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(epochs, rmse, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.savefig(f'../models/{MODEL_NAME}.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
